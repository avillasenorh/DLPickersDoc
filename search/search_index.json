{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentation for IFIC-ICM project on comparision of Deep Learning phase pickers This site contains documentation on the IFIC-ICM project to evaluate existing phase pickers based on Deep Learning. The phase pickers being considered are: GPD EQTransformer PhaseNet These pickers are being tested using 3 datasets: Seismicity prior to the 2011 El Hierro eruption Seismic crisis induced by gas injection at the CASTOR undergroung gas storage Seismicity in the Arzacq-Mauleon basin (SW France) recorded by the large-N Maupasacq experiment Data and source code in CSIC GitLab (private). Additional information on the IFIC Indico .","title":"Home"},{"location":"#documentation-for-ific-icm-project-on-comparision-of-deep-learning-phase-pickers","text":"This site contains documentation on the IFIC-ICM project to evaluate existing phase pickers based on Deep Learning. The phase pickers being considered are: GPD EQTransformer PhaseNet These pickers are being tested using 3 datasets: Seismicity prior to the 2011 El Hierro eruption Seismic crisis induced by gas injection at the CASTOR undergroung gas storage Seismicity in the Arzacq-Mauleon basin (SW France) recorded by the large-N Maupasacq experiment Data and source code in CSIC GitLab (private). Additional information on the IFIC Indico .","title":"Documentation for IFIC-ICM project on comparision of Deep Learning phase pickers"},{"location":"about/","text":"About Joint project by IFIC and ICM .","title":"About"},{"location":"about/#about","text":"Joint project by IFIC and ICM .","title":"About"},{"location":"metrics/","text":"Metrics Comparison of results from DL pickers with ground truth (high-quality picks). True positives ( t_p ) are picks done by the Deep Learning picker that coincide within a small time difference ( \\Delta t < \\epsilon ) with the picks from the labelled dataset (e.g. refined IGN picks for El Hierro pre-eruption or CASTOR sequence). True negatives ( t_n ) Comparison metrics that we will use are: Precision = { t_p \\over {t_p + f_p} } , Recall = { t_p \\over {t_p + f_n} } ,","title":"Metrics"},{"location":"metrics/#metrics","text":"Comparison of results from DL pickers with ground truth (high-quality picks). True positives ( t_p ) are picks done by the Deep Learning picker that coincide within a small time difference ( \\Delta t < \\epsilon ) with the picks from the labelled dataset (e.g. refined IGN picks for El Hierro pre-eruption or CASTOR sequence). True negatives ( t_n ) Comparison metrics that we will use are: Precision = { t_p \\over {t_p + f_p} } , Recall = { t_p \\over {t_p + f_n} } ,","title":"Metrics"},{"location":"results/","text":"Results","title":"Results"},{"location":"results/#results","text":"","title":"Results"},{"location":"datasets/castor/","text":"CASTOR 2013 earthquake crisis","title":"CASTOR"},{"location":"datasets/castor/#castor","text":"2013 earthquake crisis","title":"CASTOR"},{"location":"datasets/hierro/","text":"El Hierro We use a dataset of locations and P- and S-wave arrival times from earthquakes preceeding the eruption of 2011-2012. The dataset begins on 2011-07-21 and ends on 2011-10-09 (beginning of the eruption). It contains 31,641 earthquakes and has been obtained by reprocessing the original IGN data (Eduardo D\u00edaz Su\u00e1rez, eadiaz@mitma.es, personal communication). The following figure shows the distribution of the pre-eruption seismicity, and the location of the seismic stations from the IGN network (L\u00f3pez et al., 2012). Results are in /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/output.good File format is: picks_STA.JJJ.csv fname,itp,tp_prob,its,ts_prob /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_0,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_3000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_6000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_9000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_12000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_15000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_18000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_21000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_24000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_27000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_30000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_33000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_36000,[],[],[113],[0.340271] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_39000,[],[],[],[] L\u00f3pez, C., Blanco, M. J., Abella, R., et al. (2012). Monitoring the volcanic unrest of El Hierro (Canary Islands) before the onset of the 2011\u20132012 submarine eruption. Geophysical Research Letters, 39(13), L13303, doi: 10.1029/2012GL051846 .","title":"El Hierro"},{"location":"datasets/hierro/#el-hierro","text":"We use a dataset of locations and P- and S-wave arrival times from earthquakes preceeding the eruption of 2011-2012. The dataset begins on 2011-07-21 and ends on 2011-10-09 (beginning of the eruption). It contains 31,641 earthquakes and has been obtained by reprocessing the original IGN data (Eduardo D\u00edaz Su\u00e1rez, eadiaz@mitma.es, personal communication). The following figure shows the distribution of the pre-eruption seismicity, and the location of the seismic stations from the IGN network (L\u00f3pez et al., 2012). Results are in /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/output.good File format is: picks_STA.JJJ.csv fname,itp,tp_prob,its,ts_prob /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_0,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_3000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_6000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_9000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_12000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_15000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_18000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_21000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_24000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_27000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_30000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_33000,[],[],[],[] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_36000,[],[],[113],[0.340271] /lustre/ific.uv.es/ml/ific033/phaseDetection/phasenet/demo/Hierro/ES.CTAB.330_39000,[],[],[],[] L\u00f3pez, C., Blanco, M. J., Abella, R., et al. (2012). Monitoring the volcanic unrest of El Hierro (Canary Islands) before the onset of the 2011\u20132012 submarine eruption. Geophysical Research Letters, 39(13), L13303, doi: 10.1029/2012GL051846 .","title":"El Hierro"},{"location":"datasets/maupasacq/","text":"Maupasacq Large-N experiment","title":"Maupasacq"},{"location":"datasets/maupasacq/#maupasacq","text":"Large-N experiment","title":"Maupasacq"},{"location":"pickers/eqtransformer/","text":"EQTransformer Mousavi, S. M., Ellsworth, W. L., Zhu, W., Chuang, L. Y., & Beroza, G. C. (2020). Earthquake transformer\u2014an attentive deep-learning model for simultaneous earthquake detection and phase picking. Nat. Commun., 11(1), 3952, doi: 10.1038/s41467-020-17591-w . Installation The installation instructions for EQTransformer are found here . The installation in Artemisa was done using venv : $ git clone -b master https://git.csic.es/seismicai/eqtransformer.git $ cd eqtransformer $ python3 -m venv .venv $ source .venv/bin/activate $ pip install --upgrade pip $ pip install tensorflow \"h5py<3.0.0\" $ pip install EQTransformer -U When installing TensorFlow it is important that the version of the required package h5py is smaller than 3. Higher versions are not compatible with EQTransformer . Run How to run in Linux/macOS. How to run on Artemisa Output Output files","title":"EQTransformer"},{"location":"pickers/eqtransformer/#eqtransformer","text":"Mousavi, S. M., Ellsworth, W. L., Zhu, W., Chuang, L. Y., & Beroza, G. C. (2020). Earthquake transformer\u2014an attentive deep-learning model for simultaneous earthquake detection and phase picking. Nat. Commun., 11(1), 3952, doi: 10.1038/s41467-020-17591-w .","title":"EQTransformer"},{"location":"pickers/eqtransformer/#installation","text":"The installation instructions for EQTransformer are found here . The installation in Artemisa was done using venv : $ git clone -b master https://git.csic.es/seismicai/eqtransformer.git $ cd eqtransformer $ python3 -m venv .venv $ source .venv/bin/activate $ pip install --upgrade pip $ pip install tensorflow \"h5py<3.0.0\" $ pip install EQTransformer -U When installing TensorFlow it is important that the version of the required package h5py is smaller than 3. Higher versions are not compatible with EQTransformer .","title":"Installation"},{"location":"pickers/eqtransformer/#run","text":"How to run in Linux/macOS. How to run on Artemisa","title":"Run"},{"location":"pickers/eqtransformer/#output","text":"Output files","title":"Output"},{"location":"pickers/filterpicker/","text":"FilterPicker Lomax, A., Satriano, C., & Vassallo, M. (2012). Automatic Picker Developments and Optimization: FilterPicker-a Robust, Broadband Picker for Real-Time Seismic Monitoring and Earthquake Early Warning. Seismological Research Letters, 83(3), 531\u2013540, doi: 10.1785/gssrl.83.3.531 . Installation Download software (C version) and compile. FilterPicker executable is called picker_func_test . Run FilterPicker takes two arguments: Input file in SAC format Output file name $ picker_func_test ES.CTAB..EHZ.D.2011.300 ES.CTAB..EHZ.D.2011.300.pick The output file has the format of the location code NonLinLoc : CTAB -12345 EHZ ? P0_ + 20110922 0013 15.7600 GAU 6.000e-02 0.000e+00 1.188e+01 6.400e-01 CTAB -12345 EHZ ? P1_ ? 20110922 0019 40.3100 GAU 1.000e-02 0.000e+00 1.874e+01 1.000e-02 CTAB -12345 EHZ ? P2_ - 20110922 0023 11.7600 GAU 5.000e-02 0.000e+00 1.151e+01 1.600e-01 CTAB -12345 EHZ ? P3_ - 20110922 0031 22.3400 GAU 4.000e-02 0.000e+00 1.120e+01 3.200e-01 CTAB -12345 EHZ ? P4_ + 20110922 0038 57.8799 GAU 8.000e-02 0.000e+00 1.030e+01 6.400e-01 CTAB -12345 EHZ ? P5_ + 20110922 0100 23.5599 GAU 2.000e-02 0.000e+00 1.005e+01 8.000e-02 CTAB -12345 EHZ ? P6_ ? 20110922 0112 26.7699 GAU 1.000e-02 0.000e+00 1.639e+01 8.000e-02 CTAB -12345 EHZ ? P7_ + 20110922 0121 24.9399 GAU 4.000e-02 0.000e+00 1.223e+01 1.600e-01 CTAB -12345 EHZ ? P8_ - 20110922 0134 19.6099 GAU 4.000e-02 0.000e+00 1.014e+01 1.600e-01 The meaning of the columns is: Station name: station name or code (char*6) Instrument: instument identification for the trace for which the time pick corresponds (i.e. SP, BRB, VBB) -12345 means UNDEFINED (char*4) Component: component identification for the trace for which the time pick corresponds (i.e. Z, N, E, H) (char *4) P phase onset (char*1) description of P phase arrival onset; i, e Phase descriptor (char*6) Phase identification (i.e. P, S, PmP) First Motion: first motion direction of P arrival; c, C, u, U = compression; d, D = dilatation; +, -, Z, N; . or ? = not readable (char*1) Date (yyyymmdd) (int*6) Hour/minute (hhmm) (int*4) Seconds: seconds of phase arrival (float*7.4) Err: Error/uncertainty type; GAU (char*3) ErrMag: Error/uncertainty magnitude in seconds (expFloat*9.2) Coda duration: coda duration reading (expFloat*9.2) Amplitude: Maxumim peak-to-peak amplitude (expFloat*9.2) Period: Period of amplitude reading (expFloat*9.2) #!/bin/bash set -u # error if variable undefined set -o pipefail arcdir=/Lake/arclink year=2017 day1=60 day2=299 net=XD for ((day = $day1; day <= $day2; day++ )); do jday=$( printf \"%03d\" $day) daydir=$year.$jday mkdir $daydir cd $daydir echo \"\" echo \"\" echo \"Processing $daydir\" /bin/rm -f mseed.list find $arcdir/$year/$net -name \"$net.*.$year.$jday\" -print > mseed.list while read -r msfile; do /bin/rm -f *.SAC sac.list echo \"\" filename=${msfile##*/} echo $filename mseed2sac $msfile /bin/ls -1 *.SAC > sac.list 2> /dev/null nsac=$( cat sac.list | wc -l ) if [[ $nsac -eq 0 ]]; then echo \"ERROR: no SAC files obtained from $filename\" elif [[ $nsac -eq 1 ]]; then sacfile=$( head -1 sac.list ) picker_func_test $sacfile $filename.pick else echo \"WARNING: multiple SAC files for $filename\" (( nfile = 1 )) for sacfile in *.SAC; do npts=$( saclhdr -NPTS $sacfile ) if [[ $npts -gt 75000 ]]; then picker_func_test $sacfile temp.$nfile.pick else echo \"WARNING: segment too small: $sacfile $npts\" fi (( nfile++ )) done cat temp.[0-9]*.pick | sort -n -k7 -k8 -k9 > $filename.pick /bin/rm -f temp.[0-9]*.pick fi /bin/rm -f *.SAC sac.list done < mseed.list /bin/rm -f mseed.list cd .. done Codes and results in Artemisa The previous script loop_lomax_picker.sh is located in ~ific0331/scripts The FilterPicker executable picker_func_test is located in ~ific0331/bin The utility program mseed2sac is also located in ific0331/bin The output of running FilterPicker for the El Hierro dataset is stored in /lustre/ific.uv.es/ml/ific033/data/Hierro/FilterPicker .","title":"FilterPicker"},{"location":"pickers/filterpicker/#filterpicker","text":"Lomax, A., Satriano, C., & Vassallo, M. (2012). Automatic Picker Developments and Optimization: FilterPicker-a Robust, Broadband Picker for Real-Time Seismic Monitoring and Earthquake Early Warning. Seismological Research Letters, 83(3), 531\u2013540, doi: 10.1785/gssrl.83.3.531 .","title":"FilterPicker"},{"location":"pickers/filterpicker/#installation","text":"Download software (C version) and compile. FilterPicker executable is called picker_func_test .","title":"Installation"},{"location":"pickers/filterpicker/#run","text":"FilterPicker takes two arguments: Input file in SAC format Output file name $ picker_func_test ES.CTAB..EHZ.D.2011.300 ES.CTAB..EHZ.D.2011.300.pick The output file has the format of the location code NonLinLoc : CTAB -12345 EHZ ? P0_ + 20110922 0013 15.7600 GAU 6.000e-02 0.000e+00 1.188e+01 6.400e-01 CTAB -12345 EHZ ? P1_ ? 20110922 0019 40.3100 GAU 1.000e-02 0.000e+00 1.874e+01 1.000e-02 CTAB -12345 EHZ ? P2_ - 20110922 0023 11.7600 GAU 5.000e-02 0.000e+00 1.151e+01 1.600e-01 CTAB -12345 EHZ ? P3_ - 20110922 0031 22.3400 GAU 4.000e-02 0.000e+00 1.120e+01 3.200e-01 CTAB -12345 EHZ ? P4_ + 20110922 0038 57.8799 GAU 8.000e-02 0.000e+00 1.030e+01 6.400e-01 CTAB -12345 EHZ ? P5_ + 20110922 0100 23.5599 GAU 2.000e-02 0.000e+00 1.005e+01 8.000e-02 CTAB -12345 EHZ ? P6_ ? 20110922 0112 26.7699 GAU 1.000e-02 0.000e+00 1.639e+01 8.000e-02 CTAB -12345 EHZ ? P7_ + 20110922 0121 24.9399 GAU 4.000e-02 0.000e+00 1.223e+01 1.600e-01 CTAB -12345 EHZ ? P8_ - 20110922 0134 19.6099 GAU 4.000e-02 0.000e+00 1.014e+01 1.600e-01 The meaning of the columns is: Station name: station name or code (char*6) Instrument: instument identification for the trace for which the time pick corresponds (i.e. SP, BRB, VBB) -12345 means UNDEFINED (char*4) Component: component identification for the trace for which the time pick corresponds (i.e. Z, N, E, H) (char *4) P phase onset (char*1) description of P phase arrival onset; i, e Phase descriptor (char*6) Phase identification (i.e. P, S, PmP) First Motion: first motion direction of P arrival; c, C, u, U = compression; d, D = dilatation; +, -, Z, N; . or ? = not readable (char*1) Date (yyyymmdd) (int*6) Hour/minute (hhmm) (int*4) Seconds: seconds of phase arrival (float*7.4) Err: Error/uncertainty type; GAU (char*3) ErrMag: Error/uncertainty magnitude in seconds (expFloat*9.2) Coda duration: coda duration reading (expFloat*9.2) Amplitude: Maxumim peak-to-peak amplitude (expFloat*9.2) Period: Period of amplitude reading (expFloat*9.2) #!/bin/bash set -u # error if variable undefined set -o pipefail arcdir=/Lake/arclink year=2017 day1=60 day2=299 net=XD for ((day = $day1; day <= $day2; day++ )); do jday=$( printf \"%03d\" $day) daydir=$year.$jday mkdir $daydir cd $daydir echo \"\" echo \"\" echo \"Processing $daydir\" /bin/rm -f mseed.list find $arcdir/$year/$net -name \"$net.*.$year.$jday\" -print > mseed.list while read -r msfile; do /bin/rm -f *.SAC sac.list echo \"\" filename=${msfile##*/} echo $filename mseed2sac $msfile /bin/ls -1 *.SAC > sac.list 2> /dev/null nsac=$( cat sac.list | wc -l ) if [[ $nsac -eq 0 ]]; then echo \"ERROR: no SAC files obtained from $filename\" elif [[ $nsac -eq 1 ]]; then sacfile=$( head -1 sac.list ) picker_func_test $sacfile $filename.pick else echo \"WARNING: multiple SAC files for $filename\" (( nfile = 1 )) for sacfile in *.SAC; do npts=$( saclhdr -NPTS $sacfile ) if [[ $npts -gt 75000 ]]; then picker_func_test $sacfile temp.$nfile.pick else echo \"WARNING: segment too small: $sacfile $npts\" fi (( nfile++ )) done cat temp.[0-9]*.pick | sort -n -k7 -k8 -k9 > $filename.pick /bin/rm -f temp.[0-9]*.pick fi /bin/rm -f *.SAC sac.list done < mseed.list /bin/rm -f mseed.list cd .. done","title":"Run"},{"location":"pickers/filterpicker/#codes-and-results-in-artemisa","text":"The previous script loop_lomax_picker.sh is located in ~ific0331/scripts The FilterPicker executable picker_func_test is located in ~ific0331/bin The utility program mseed2sac is also located in ific0331/bin The output of running FilterPicker for the El Hierro dataset is stored in /lustre/ific.uv.es/ml/ific033/data/Hierro/FilterPicker .","title":"Codes and results in Artemisa"},{"location":"pickers/gpd/","text":"Generalized Phase Detector (GPD) Ross, Z. E., Meier, M.-A., Hauksson, E., & Heaton, T. H. (2018). Generalized Phase Detection with Deep Learning. Bulletin of the Seismological Society of America, 108(5A), 2894\u20132901, doi: 10.1785/0120180080 . Installation Requirements Run How to run in Linux/macOS. How to run on Artemisa Output Output files","title":"GPD"},{"location":"pickers/gpd/#generalized-phase-detector-gpd","text":"Ross, Z. E., Meier, M.-A., Hauksson, E., & Heaton, T. H. (2018). Generalized Phase Detection with Deep Learning. Bulletin of the Seismological Society of America, 108(5A), 2894\u20132901, doi: 10.1785/0120180080 .","title":"Generalized Phase Detector (GPD)"},{"location":"pickers/gpd/#installation","text":"Requirements","title":"Installation"},{"location":"pickers/gpd/#run","text":"How to run in Linux/macOS. How to run on Artemisa","title":"Run"},{"location":"pickers/gpd/#output","text":"Output files","title":"Output"},{"location":"pickers/phasenet/","text":"PhaseNet Zhu, W., & Beroza, G. C. (2019). PhaseNet: A Deep-Neural-Network-Based Seismic Arrival Time Picking Method. Geophysical Journal International, 216(1), 261\u2013273, doi: 10.1093/gji/ggy423 . New version added since original repo was downloaded. Installation Requirements New version (tried on 2022-09-18): $ git clone https://github.com/wayneweiqiang/PhaseNet.git $ cd PhaseNet $ conda env create -f env.yml $ conda activate phasenet Run How to run in Linux/macOS. How to run on Artemisa Run the new version Here we assume that we have installed PhaseNet in the directory ${HOME}/repos/PhaseNet and we want to run the predictions for the miniSEED data in ${HOME}/repos/PhaseNet/demo . First we need to create a csv file with the list of miniSEED files to process: fname,E,N,Z CCC.mseed,HHE,HHN,HHZ ... To run the test data in the directory demo : $ cd $ cd repos/PhaseNet $ python phasenet/predict.py --model=model/190703-214543 --data_list=demo/fname.csv \\ --data_dir=demo/mseed --result_dir=demo/results --format=mseed --plot_figure This will produce the output in the directory ${HOME}/repos/PhaseNet/demo/results , Old output Old version outputs a csv and a pkl (pickle) file. The format of the csv file is: fname,itp,tp_prob,its,ts_prob CA.CBEU..HH.mseed_0,[],[],[],[] CA.AVIN..HN.mseed_0,[],[],[],[] CA.CBRU..HH.mseed_0,[],[],[],[] CA.BAIN..HN.mseed_0,[],[],[],[] CA.BLAN..HN.mseed_0,[],[],[],[] CA.BAJU..HN.mseed_0,[],[],[],[] CA.CAVN..HH.mseed_0,[],[],[],[] CA.CBUD..HH.mseed_0,[],[],[],[] CA.CBEU..HH.mseed_3000,[],[],[],[] CA.AVIN..HN.mseed_3000,[2072],[0.36653],[],[] CA.BLAN..HN.mseed_3000,[],[],[],[] CA.BAIN..HN.mseed_3000,[],[],[],[] CA.BAJU..HN.mseed_3000,[],[],[],[] CA.CAVN..HH.mseed_3000,[2284],[0.884308],[],[] CA.CBUD..HH.mseed_3000,[251],[0.78194],[530],[0.934841] CA.CBRU..HH.mseed_3000,[],[],[],[] CA.BLAN..HN.mseed_6000,[863],[0.733137],[],[] ... This format can not be used and is re-written to the so-called pick format: CA.CMAS..HH P 2020-10-19T19:53:09.600000000 0.94159900 1 CA.CMAS..HH S 2020-10-19T19:53:19.370000000 0.69820100 1 Also markers format to plot with snuffler : # Snuffler Markers File Version 0.2 phase: 2020-10-19 19:53:09.600000000 0 CA.CMAS..HHZ None None None P None False phase: 2020-10-19 19:53:19.370000000 0 CA.CMAS..HHN None None None S None False New output ``` file_name,begin_time,station_id,phase_index,phase_time,phase_score,phase_type CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,18021,2019-07-04T17:03:00.208,0.956,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,24742,2019-07-04T17:04:07.418,0.838,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,30658,2019-07-04T17:05:06.578,0.78,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,35298,2019-07-04T17:05:52.978,0.442,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,38846,2019-07-04T17:06:28.458,0.493,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,38900,2019-07-04T17:06:28.998,0.435,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,51138,2019-07-04T17:08:31.378,0.971,P ... CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2516038,2019-07-04T23:59:20.378,0.37,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2516598,2019-07-04T23:59:25.978,0.961,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2519071,2019-07-04T23:59:50.708,0.838,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,18412,2019-07-04T17:03:04.118,0.927,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,25121,2019-07-04T17:04:11.208,0.629,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,31022,2019-07-04T17:05:10.218,0.309,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,31401,2019-07-04T17:05:14.008,0.815,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,35681,2019-07-04T17:05:56.808,0.537,S ...","title":"PhaseNet"},{"location":"pickers/phasenet/#phasenet","text":"Zhu, W., & Beroza, G. C. (2019). PhaseNet: A Deep-Neural-Network-Based Seismic Arrival Time Picking Method. Geophysical Journal International, 216(1), 261\u2013273, doi: 10.1093/gji/ggy423 . New version added since original repo was downloaded.","title":"PhaseNet"},{"location":"pickers/phasenet/#installation","text":"Requirements New version (tried on 2022-09-18): $ git clone https://github.com/wayneweiqiang/PhaseNet.git $ cd PhaseNet $ conda env create -f env.yml $ conda activate phasenet","title":"Installation"},{"location":"pickers/phasenet/#run","text":"How to run in Linux/macOS. How to run on Artemisa","title":"Run"},{"location":"pickers/phasenet/#run-the-new-version","text":"Here we assume that we have installed PhaseNet in the directory ${HOME}/repos/PhaseNet and we want to run the predictions for the miniSEED data in ${HOME}/repos/PhaseNet/demo . First we need to create a csv file with the list of miniSEED files to process: fname,E,N,Z CCC.mseed,HHE,HHN,HHZ ... To run the test data in the directory demo : $ cd $ cd repos/PhaseNet $ python phasenet/predict.py --model=model/190703-214543 --data_list=demo/fname.csv \\ --data_dir=demo/mseed --result_dir=demo/results --format=mseed --plot_figure This will produce the output in the directory ${HOME}/repos/PhaseNet/demo/results ,","title":"Run the new version"},{"location":"pickers/phasenet/#old-output","text":"Old version outputs a csv and a pkl (pickle) file. The format of the csv file is: fname,itp,tp_prob,its,ts_prob CA.CBEU..HH.mseed_0,[],[],[],[] CA.AVIN..HN.mseed_0,[],[],[],[] CA.CBRU..HH.mseed_0,[],[],[],[] CA.BAIN..HN.mseed_0,[],[],[],[] CA.BLAN..HN.mseed_0,[],[],[],[] CA.BAJU..HN.mseed_0,[],[],[],[] CA.CAVN..HH.mseed_0,[],[],[],[] CA.CBUD..HH.mseed_0,[],[],[],[] CA.CBEU..HH.mseed_3000,[],[],[],[] CA.AVIN..HN.mseed_3000,[2072],[0.36653],[],[] CA.BLAN..HN.mseed_3000,[],[],[],[] CA.BAIN..HN.mseed_3000,[],[],[],[] CA.BAJU..HN.mseed_3000,[],[],[],[] CA.CAVN..HH.mseed_3000,[2284],[0.884308],[],[] CA.CBUD..HH.mseed_3000,[251],[0.78194],[530],[0.934841] CA.CBRU..HH.mseed_3000,[],[],[],[] CA.BLAN..HN.mseed_6000,[863],[0.733137],[],[] ... This format can not be used and is re-written to the so-called pick format: CA.CMAS..HH P 2020-10-19T19:53:09.600000000 0.94159900 1 CA.CMAS..HH S 2020-10-19T19:53:19.370000000 0.69820100 1 Also markers format to plot with snuffler : # Snuffler Markers File Version 0.2 phase: 2020-10-19 19:53:09.600000000 0 CA.CMAS..HHZ None None None P None False phase: 2020-10-19 19:53:19.370000000 0 CA.CMAS..HHN None None None S None False","title":"Old output"},{"location":"pickers/phasenet/#new-output","text":"``` file_name,begin_time,station_id,phase_index,phase_time,phase_score,phase_type CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,18021,2019-07-04T17:03:00.208,0.956,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,24742,2019-07-04T17:04:07.418,0.838,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,30658,2019-07-04T17:05:06.578,0.78,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,35298,2019-07-04T17:05:52.978,0.442,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,38846,2019-07-04T17:06:28.458,0.493,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,38900,2019-07-04T17:06:28.998,0.435,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,51138,2019-07-04T17:08:31.378,0.971,P ... CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2516038,2019-07-04T23:59:20.378,0.37,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2516598,2019-07-04T23:59:25.978,0.961,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,2519071,2019-07-04T23:59:50.708,0.838,P CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,18412,2019-07-04T17:03:04.118,0.927,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,25121,2019-07-04T17:04:11.208,0.629,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,31022,2019-07-04T17:05:10.218,0.309,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,31401,2019-07-04T17:05:14.008,0.815,S CCC.mseed,2019-07-04T16:59:59.998,CCC.mseed,35681,2019-07-04T17:05:56.808,0.537,S ...","title":"New output"},{"location":"pickers/picknet/","text":"PickNet Wang, J., Xiao, Z., Liu, C., Zhao, D., & Yao, Z. (2019). Deep Learning for Picking Seismic Arrival Times. Journal of Geophysical Research: Solid Earth, 124(7), 6612\u20136624, doi: 10.1029/2019JB017536 . Installation According to the manual, the installation can be done with conda: $ conda create -n picknet python=3.6 tensorflow=1.8 cudatoolkit=X.X pyyaml matplotlib However, this produces an error. We have tried this alternative: $ conda create -n picknet python=3.6 $ conda activate picknet $ conda install -c conda-forge obspy # this also installs matplotlib $ conda install pyyaml $ conda install pyproj # needed for gen_input_for_pick.py $ pip install tensorflow==1.8 $ conda install numpy==1.16.2 # gen_tomo_arrivals_inputfile_p_s.py does not work with 1.19.5 We did not include the cudatoolkit option because we are testing the code in a computer without a NVIDA GPU. Download waveform data files The first step in the tutorial is to download waveform data from IRIS. For this we need a list of events to extract (catalog), a list of stations, and a way to request the waveform data to the data center. This is done with the script download_data.py located in the directory PickingDataFromIRISExample : $ cd PickingDataFromIRISExample $ python download_data.py NOTE: directory ori_data/events must exist before running the script, but can be empty ( catalog.xml is created by the script). The other directories ori_data/stations and ori_data/waveforms are created by the script. Running this script produces the following files: ori_data/events/catalog.xml : catalog file in QuakeML format. ori_data/stations/NET.STA.xml : station files in StationXML format. NET indicates the network code, and STA the station code (e.g. BK.YBH.xml ). ori_data/waveforms/En/*.mseed : waveform files in miniSEED format. En is the directory that contains the waveform data for event number n in catalog.xml . The waveform files *.mseed have names such as: UW.BST17..HHZ__20190623T223810Z__20190623T224910Z.mseed The event number n starts with 0. Running this script (as of 2021-01-22), it obtains only 5 events, with the corresponding event directories E0 to E4 . Apparently when the script was created, it obtained 6 events. This will produce a problem in the script of the following step because the number of events it expects (6) is hard-wired in the code. There seems to be an additional off-by-one logic problem in the scripts, because some output files contain the prefix E0_E6_ indicating that there are 7 events, from index 0 to 6, while in reality the test data contains 6 events, with indices from 0 to 5 (or 5 event with indices from 0 to 4 in we re-run the data extraction script in 2021). If we change the value of end_e to 5, then the script runs correctly, and generates the preprocessed files in directory input_output , some with prefixes E0_E5_ (which should be E0_E4_ ). Waveform pre-processing The next step is to prepare the extracted raw waveforms for picking. This pre-processing consists of 3 steps: Rotate the horizontal components to radial and transverse Cut the waveforms to 12 s windowns centered on the theoretical P wave arrival for the vertical component and 16 s windows centered on the theoretical S wave arrival for the radial and transverse components. Remove the mean and normalize by the absolute value of the maximum amplitude. (The order of these steps is not clear, need to check the source code) $ python gen_input_for_pick.py This script generates its output files in the directory input_output . First it generates the P and S time windows and writes them in NumPy binary format, in the directories P_slices and S_slices respectively, with a subdirectory for each event: P_slices/E?/input.npy P_slices/E?/sta_info.npy S_slices/E?/input.npy S_slices/E?/sta_info.npy Then it combines the data from all the events into a single NumPy binary file, located in the directories P_input and S_input : P_input/E0_E6_info.npy P_input/E0_E6_input.npy S_input/E0_E6_RT_info.npy S_input/E0_E6_RT_input.npy As mentioned before, if we try to run this script with data extracted in 2021 it crashes. The problem is that it expects 6 event directories (from E0 to E5 ), and the download script download_data.py only produced 5 event directorioes (from E0 to E4 ). To make the script run correctly with 5 events, we need to edit line 406 in gen_input_for_pick.py and set the variable end_e to 5. if __name__ == '__main__': print('START PROCESSING') start_e = 0 end_e = 5 # originally set to 6 Picking In order to run the phase picking, two parameter files are needed inside the directory input_output : P_config.yaml and S_config.yaml . These files contains parameters for the training, etc. For the picking, the most relevant difference between both files is the trained model to use. Here is the contents of P_config.yaml : # location of snapshot and tensorbaord summary events save_dir: fcn/trained_models/P_wave/ # training batch size, decide with your GPU size batch_size_train: 20 # validation batch size, ran every val_interval batch_size_val: 20 # test batch size batch_size_test: 2000 # split training data for trainig/validation train_split: 0.95 # maximum iterations to run epoc == 30k/batch_size max_iterations: 800005 # optimizer params (not used currently Adam is used by default) optimizer: 'adam' optimizer_params: learning_rate: 0.001 weight_decay: 0.0002 # Loss for layer fusion loss_weights: 1.0 # save snapshot every save_interval iterations save_interval: 1000 # validate on held out dataset val_interval: 1000 # print loss every print_interval print_interval: 100 # learning rate decay (Not used with Adam currently) learning_rate_decay: 0.1 # Apply weighted_cross_entropy_loss to outputs from each side layer # Setting to false only loss after last conv layer is computed deep_supervision: True # Targets are continous if True else binary {0, 1} target_regression: True training: filename: NOT_FOR_TRAINING # length_before: 400 data_width: 1200 data_height: 1 n_channels: 1 trace_per_collect: 4 rand_dev: 300 # testing data testing: filename: PickingDataFromIRISExample/input_output/P_input/E0_E6_input data_width: 1200 data_height: 1 n_channels: 1 limit_left: 300 limit_right: 900 # use snapshot after test_snapshot intervals for testing test_snapshot: 330000 # Apply testing_threshold after relu testing_threshold: 0.0 #available choices: HED, SRN, PickNet using_model: PickNet #block1 conv size b1_convh: 1 b1_convw: 32 #block2 conv size b2_convh: 1 b2_convw: 16 #block3 conv size b3_convh: 1 b3_convw: 8 #block4 conv size b4_convh: 1 b4_convw: 4 #block5 conv size b5_convh: 1 b5_convw: 2 The parameter testing: filename contains the E0_E6_input prefix. If we pick a different number of events, this parameter has to be changed. To run the picking go to the parent directory of the repository and type: $ cd .. $ python seismic_pick_run.py --test \\ --config-file PickingDataFromIRISExample/input_output/P_config.yaml # for P waves $ python seismic_pick_run.py --test \\ --config-file PickingDataFromIRISExample/input_output/S_config.yaml # for S waves These scripts will produce the following files inside the directory PickingDataFromIRISExample : For P waves: input_output/P_input/E0_E6_input_fuse_picks.npy input_output/P_input/E0_E6_input_output.npy For S waves: input_output/S_input/E0_E6_RT_input_fuse_picks.npy input_output/S_input/E0_E6_RT_input_output.npy Post-processing The output of the picking script seismic_pick_run.py are files in NumPy binary format. To obtain the picks in readable form and see plots of the results we need to run additional scripts. First we need to run: $ cd PickingDataFromIRISExample $ python ViewAndGatherP.py input_output/P_input E0_E6_ 1 # for P waves $ python ViewAndGatherS.py input_output/S_input E0_E6_RT_ 1 # for S waves These two scripts produce the following output files. For P waves: P_input/E0_E6_msta_input.npy P_input/E0_E6_View/En.png : png files for each event n For S waves: S_input/E0_E6_RT_msta_input.npy S_input/E0_E6_RT_View/En.png : png files for each event n Except for the png files, the results are in NumPy binary format and therefore not yet in human readable format. In order to convert the output to text format we have to run the following script: $ python gen_tomo_arrivals_inputfile_p_s.py 'input_output/P_input/' 'input_output/S_input/' 'txt_pickfile/' IRIS This script will create a directory named txt_pickfile with the following files: txt_pickfile/IRISdata_code_dict.npy txt_pickfile/IRISpicks.txt However, the script in its original form does not work, giving the following error: File \"gen_tomo_arrivals_inputfile_p_s.py\", line 34, in <module> picks_dict = np.load(str(pickfile))[()] File \"/Users/antonio/opt/anaconda3/envs/picknet/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 440, in load pickle_kwargs=pickle_kwargs) File \"/Users/antonio/opt/anaconda3/envs/picknet/lib/python3.6/site-packages/numpy/lib/format.py\", line 727, in read_array raise ValueError(\"Object arrays cannot be loaded when \" ValueError: Object arrays cannot be loaded when allow_pickle=False This error occurs in the following line: for pickfile in picks_dir.glob('*_msta_input.npy'): picks_dict = np.load(str(pickfile))[()] This seems to be related to the NumPy version. The version originally installed is 1.19.5. Downgrading NumPy to 1.16.2 ( conda install numpy==1.16.2 ) fixes the issue. This also eliminates most of the warnings produced when running seismic_pick_run.py . One final step is to generate the station list: $ python gen_tomo_stations_inputfile.py 'ori_data/stations/' 'txt_pickfile/' This script produces the following output: txt_pickfile/stations.txt","title":"PickNet"},{"location":"pickers/picknet/#picknet","text":"Wang, J., Xiao, Z., Liu, C., Zhao, D., & Yao, Z. (2019). Deep Learning for Picking Seismic Arrival Times. Journal of Geophysical Research: Solid Earth, 124(7), 6612\u20136624, doi: 10.1029/2019JB017536 .","title":"PickNet"},{"location":"pickers/picknet/#installation","text":"According to the manual, the installation can be done with conda: $ conda create -n picknet python=3.6 tensorflow=1.8 cudatoolkit=X.X pyyaml matplotlib However, this produces an error. We have tried this alternative: $ conda create -n picknet python=3.6 $ conda activate picknet $ conda install -c conda-forge obspy # this also installs matplotlib $ conda install pyyaml $ conda install pyproj # needed for gen_input_for_pick.py $ pip install tensorflow==1.8 $ conda install numpy==1.16.2 # gen_tomo_arrivals_inputfile_p_s.py does not work with 1.19.5 We did not include the cudatoolkit option because we are testing the code in a computer without a NVIDA GPU.","title":"Installation"},{"location":"pickers/picknet/#download-waveform-data-files","text":"The first step in the tutorial is to download waveform data from IRIS. For this we need a list of events to extract (catalog), a list of stations, and a way to request the waveform data to the data center. This is done with the script download_data.py located in the directory PickingDataFromIRISExample : $ cd PickingDataFromIRISExample $ python download_data.py NOTE: directory ori_data/events must exist before running the script, but can be empty ( catalog.xml is created by the script). The other directories ori_data/stations and ori_data/waveforms are created by the script. Running this script produces the following files: ori_data/events/catalog.xml : catalog file in QuakeML format. ori_data/stations/NET.STA.xml : station files in StationXML format. NET indicates the network code, and STA the station code (e.g. BK.YBH.xml ). ori_data/waveforms/En/*.mseed : waveform files in miniSEED format. En is the directory that contains the waveform data for event number n in catalog.xml . The waveform files *.mseed have names such as: UW.BST17..HHZ__20190623T223810Z__20190623T224910Z.mseed The event number n starts with 0. Running this script (as of 2021-01-22), it obtains only 5 events, with the corresponding event directories E0 to E4 . Apparently when the script was created, it obtained 6 events. This will produce a problem in the script of the following step because the number of events it expects (6) is hard-wired in the code. There seems to be an additional off-by-one logic problem in the scripts, because some output files contain the prefix E0_E6_ indicating that there are 7 events, from index 0 to 6, while in reality the test data contains 6 events, with indices from 0 to 5 (or 5 event with indices from 0 to 4 in we re-run the data extraction script in 2021). If we change the value of end_e to 5, then the script runs correctly, and generates the preprocessed files in directory input_output , some with prefixes E0_E5_ (which should be E0_E4_ ).","title":"Download waveform data files"},{"location":"pickers/picknet/#waveform-pre-processing","text":"The next step is to prepare the extracted raw waveforms for picking. This pre-processing consists of 3 steps: Rotate the horizontal components to radial and transverse Cut the waveforms to 12 s windowns centered on the theoretical P wave arrival for the vertical component and 16 s windows centered on the theoretical S wave arrival for the radial and transverse components. Remove the mean and normalize by the absolute value of the maximum amplitude. (The order of these steps is not clear, need to check the source code) $ python gen_input_for_pick.py This script generates its output files in the directory input_output . First it generates the P and S time windows and writes them in NumPy binary format, in the directories P_slices and S_slices respectively, with a subdirectory for each event: P_slices/E?/input.npy P_slices/E?/sta_info.npy S_slices/E?/input.npy S_slices/E?/sta_info.npy Then it combines the data from all the events into a single NumPy binary file, located in the directories P_input and S_input : P_input/E0_E6_info.npy P_input/E0_E6_input.npy S_input/E0_E6_RT_info.npy S_input/E0_E6_RT_input.npy As mentioned before, if we try to run this script with data extracted in 2021 it crashes. The problem is that it expects 6 event directories (from E0 to E5 ), and the download script download_data.py only produced 5 event directorioes (from E0 to E4 ). To make the script run correctly with 5 events, we need to edit line 406 in gen_input_for_pick.py and set the variable end_e to 5. if __name__ == '__main__': print('START PROCESSING') start_e = 0 end_e = 5 # originally set to 6","title":"Waveform pre-processing"},{"location":"pickers/picknet/#picking","text":"In order to run the phase picking, two parameter files are needed inside the directory input_output : P_config.yaml and S_config.yaml . These files contains parameters for the training, etc. For the picking, the most relevant difference between both files is the trained model to use. Here is the contents of P_config.yaml : # location of snapshot and tensorbaord summary events save_dir: fcn/trained_models/P_wave/ # training batch size, decide with your GPU size batch_size_train: 20 # validation batch size, ran every val_interval batch_size_val: 20 # test batch size batch_size_test: 2000 # split training data for trainig/validation train_split: 0.95 # maximum iterations to run epoc == 30k/batch_size max_iterations: 800005 # optimizer params (not used currently Adam is used by default) optimizer: 'adam' optimizer_params: learning_rate: 0.001 weight_decay: 0.0002 # Loss for layer fusion loss_weights: 1.0 # save snapshot every save_interval iterations save_interval: 1000 # validate on held out dataset val_interval: 1000 # print loss every print_interval print_interval: 100 # learning rate decay (Not used with Adam currently) learning_rate_decay: 0.1 # Apply weighted_cross_entropy_loss to outputs from each side layer # Setting to false only loss after last conv layer is computed deep_supervision: True # Targets are continous if True else binary {0, 1} target_regression: True training: filename: NOT_FOR_TRAINING # length_before: 400 data_width: 1200 data_height: 1 n_channels: 1 trace_per_collect: 4 rand_dev: 300 # testing data testing: filename: PickingDataFromIRISExample/input_output/P_input/E0_E6_input data_width: 1200 data_height: 1 n_channels: 1 limit_left: 300 limit_right: 900 # use snapshot after test_snapshot intervals for testing test_snapshot: 330000 # Apply testing_threshold after relu testing_threshold: 0.0 #available choices: HED, SRN, PickNet using_model: PickNet #block1 conv size b1_convh: 1 b1_convw: 32 #block2 conv size b2_convh: 1 b2_convw: 16 #block3 conv size b3_convh: 1 b3_convw: 8 #block4 conv size b4_convh: 1 b4_convw: 4 #block5 conv size b5_convh: 1 b5_convw: 2 The parameter testing: filename contains the E0_E6_input prefix. If we pick a different number of events, this parameter has to be changed. To run the picking go to the parent directory of the repository and type: $ cd .. $ python seismic_pick_run.py --test \\ --config-file PickingDataFromIRISExample/input_output/P_config.yaml # for P waves $ python seismic_pick_run.py --test \\ --config-file PickingDataFromIRISExample/input_output/S_config.yaml # for S waves These scripts will produce the following files inside the directory PickingDataFromIRISExample : For P waves: input_output/P_input/E0_E6_input_fuse_picks.npy input_output/P_input/E0_E6_input_output.npy For S waves: input_output/S_input/E0_E6_RT_input_fuse_picks.npy input_output/S_input/E0_E6_RT_input_output.npy","title":"Picking"},{"location":"pickers/picknet/#post-processing","text":"The output of the picking script seismic_pick_run.py are files in NumPy binary format. To obtain the picks in readable form and see plots of the results we need to run additional scripts. First we need to run: $ cd PickingDataFromIRISExample $ python ViewAndGatherP.py input_output/P_input E0_E6_ 1 # for P waves $ python ViewAndGatherS.py input_output/S_input E0_E6_RT_ 1 # for S waves These two scripts produce the following output files. For P waves: P_input/E0_E6_msta_input.npy P_input/E0_E6_View/En.png : png files for each event n For S waves: S_input/E0_E6_RT_msta_input.npy S_input/E0_E6_RT_View/En.png : png files for each event n Except for the png files, the results are in NumPy binary format and therefore not yet in human readable format. In order to convert the output to text format we have to run the following script: $ python gen_tomo_arrivals_inputfile_p_s.py 'input_output/P_input/' 'input_output/S_input/' 'txt_pickfile/' IRIS This script will create a directory named txt_pickfile with the following files: txt_pickfile/IRISdata_code_dict.npy txt_pickfile/IRISpicks.txt However, the script in its original form does not work, giving the following error: File \"gen_tomo_arrivals_inputfile_p_s.py\", line 34, in <module> picks_dict = np.load(str(pickfile))[()] File \"/Users/antonio/opt/anaconda3/envs/picknet/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 440, in load pickle_kwargs=pickle_kwargs) File \"/Users/antonio/opt/anaconda3/envs/picknet/lib/python3.6/site-packages/numpy/lib/format.py\", line 727, in read_array raise ValueError(\"Object arrays cannot be loaded when \" ValueError: Object arrays cannot be loaded when allow_pickle=False This error occurs in the following line: for pickfile in picks_dir.glob('*_msta_input.npy'): picks_dict = np.load(str(pickfile))[()] This seems to be related to the NumPy version. The version originally installed is 1.19.5. Downgrading NumPy to 1.16.2 ( conda install numpy==1.16.2 ) fixes the issue. This also eliminates most of the warnings produced when running seismic_pick_run.py . One final step is to generate the station list: $ python gen_tomo_stations_inputfile.py 'ori_data/stations/' 'txt_pickfile/' This script produces the following output: txt_pickfile/stations.txt","title":"Post-processing"}]}